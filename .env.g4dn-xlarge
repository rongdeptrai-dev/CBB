# AWS G4dn.xlarge Configuration
# T4 GPU (16GB VRAM) + 16GB RAM + 4 vCPUs
# Optimized for high-performance AI customer service

# ========== API Configuration ==========
API_PORT=8000
DATABASE_URL=sqlite:///cyberbot_g4dn.db
API_KEY=your_secure_api_key_here

# ========== GPU Model Configuration ==========
USE_HUGGINGFACE=true

# Primary Vietnamese conversation model (larger for GPU)
HF_MODEL_NAME=VietAI/vit5-large
HF_MODEL_TYPE=t5
HF_USE_GPU=true

# Enhanced generation parameters for GPU
HF_MAX_LENGTH=512
HF_MAX_NEW_TOKENS=256
HF_TEMPERATURE=0.8
HF_TOP_P=0.9
HF_TOP_K=50
HF_DO_SAMPLE=true
HF_NUM_BEAMS=4

# G4dn.xlarge optimizations (T4 GPU, 16GB VRAM, 16GB RAM, 4 vCPUs)
HF_BATCH_SIZE=8
HF_NUM_THREADS=4
HF_INTRAOP_THREADS=4
HF_INTEROP_THREADS=2
MAX_MEMORY_USAGE=12.0
MAX_VRAM_USAGE=14.0

# ========== Advanced AI Features ==========
# Multi-model customer service enhancement
CONVERSATION_MODEL=microsoft/DialoGPT-medium
EMOTION_MODEL=j-hartmann/emotion-english-distilroberta-base
SENTIMENT_MODEL=cardiffnlp/twitter-roberta-base-sentiment-latest

# Feature toggles
ENABLE_EMOTION_DETECTION=true
ENABLE_SENTIMENT_ANALYSIS=true
ENABLE_MULTI_MODEL_ENSEMBLE=true

# ========== Alternative Models (backup options) ==========
# For Vietnamese specific tasks
# HF_MODEL_NAME=vinai/phobert-base
# HF_MODEL_NAME=VietAI/vit5-base

# For English conversation
# HF_MODEL_NAME=microsoft/DialoGPT-large
# HF_MODEL_NAME=facebook/blenderbot-400M-distill

# For multilingual support
# HF_MODEL_NAME=google/mt5-large
# HF_MODEL_NAME=facebook/mbart-large-50-many-to-many-mmt

# ========== Legacy Llama Configuration (fallback) ==========
MODEL_PATH=PhoGPT-4B-Chat-Q8_0.gguf
MODEL_TEMPERATURE=0.7
MODEL_MAX_LENGTH=80
MODEL_CTX_SIZE=512

# ========== Vector Database (Pinecone) ==========
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENV=gcp-starter
PINECONE_INDEX_NAME=cyberbot-memory-g4dn

# ========== Knowledge Graph (Neo4j) ==========
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# ========== Telegram Alerts ==========
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
TELEGRAM_CHAT_IDS=your_chat_id_1,your_chat_id_2

# ========== Performance Tuning ==========
# GPU Memory Management
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024
CUDA_VISIBLE_DEVICES=0

# PyTorch optimizations
OMP_NUM_THREADS=4
MKL_NUM_THREADS=4
TOKENIZERS_PARALLELISM=true

# ========== Logging & Monitoring ==========
LOG_LEVEL=INFO
ENABLE_PERFORMANCE_LOGGING=true
ENABLE_GPU_MONITORING=true
ENABLE_MEMORY_MONITORING=true

# ========== Customer Service Optimization ==========
MAX_CONVERSATION_HISTORY=20
RESPONSE_TIMEOUT=30
MAX_CONCURRENT_REQUESTS=50
ENABLE_RESPONSE_CACHING=true
CACHE_TTL=300
